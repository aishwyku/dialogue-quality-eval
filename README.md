# Dialogue Quality Evaluation Sample

Sample project showing manual evaluation of AI-generated dialogues.

## Data fields
- ai_response, fluency_score, relevance_score, notes

## Scripts
- `evaluate_dialogues.py`: Computes average fluency and relevance.

## Purpose
- Demonstrates high-judgment annotation and documentation.
